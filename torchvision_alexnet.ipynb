{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.0.1\n",
      "Torchvision Version:  0.2.2\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "import random\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms\n",
    "#   to the ImageFolder structure\n",
    "data_dir = \"./data/hymenoptera_data\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 16\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                if (labels.shape[0] < batch_size):\n",
    "                        continue\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    outputs = model(inputs)\n",
    "                    print('outputs')\n",
    "                    print(outputs.shape)\n",
    "                    print('labels')\n",
    "                    print(labels.shape)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        print('backward works')\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Dropout(p=0.5)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(num_classes):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "    \n",
    "    model_ft = models.alexnet(pretrained=False)\n",
    "    num_ftrs = model_ft.classifier[6].in_features\n",
    "    model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "    input_size = 224\n",
    "    \n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(num_classes)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t features.0.weight\n",
      "\t features.0.bias\n",
      "\t features.3.weight\n",
      "\t features.3.bias\n",
      "\t features.6.weight\n",
      "\t features.6.bias\n",
      "\t features.8.weight\n",
      "\t features.8.bias\n",
      "\t features.10.weight\n",
      "\t features.10.bias\n",
      "\t classifier.1.weight\n",
      "\t classifier.1.bias\n",
      "\t classifier.4.weight\n",
      "\t classifier.4.bias\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "for name,param in model_ft.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    \"\"\"\n",
    "    Container for all sampling methods that can be used in conjunction with the respective loss functions.\n",
    "    Based on batch-wise sampling, i.e. given a batch of training data, sample useful data tuples that are\n",
    "    used to train the network more efficiently.\n",
    "    \"\"\"\n",
    "    def __init__(self, method='random'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            method: str, name of sampling method to use.\n",
    "        Returns:\n",
    "            Nothing!\n",
    "        \"\"\"\n",
    "        self.method = method\n",
    "        if method=='semihard':\n",
    "            self.give = self.semihardsampling\n",
    "        elif method=='distance':\n",
    "            self.give = self.distanceweightedsampling\n",
    "        elif method=='npair':\n",
    "            self.give = self.npairsampling\n",
    "        elif method=='random':\n",
    "            self.give = self.randomsampling\n",
    "\n",
    "    def randomsampling(self, batch, labels):\n",
    "        \"\"\"\n",
    "        This methods finds all available triplets in a batch given by the classes provided in labels, and randomly\n",
    "        selects <len(batch)> triplets.\n",
    "        Args:\n",
    "            batch:  np.ndarray or torch.Tensor, batch-wise embedded training samples.\n",
    "            labels: np.ndarray or torch.Tensor, ground truth labels corresponding to batch.\n",
    "        Returns:\n",
    "            list of sampled data tuples containing reference indices to the position IN THE BATCH.\n",
    "        \"\"\"\n",
    "        if isinstance(labels, torch.Tensor): labels = labels.detach().numpy()\n",
    "        unique_classes = np.unique(labels)\n",
    "        #print('unique_classes')\n",
    "        #print(unique_classes)\n",
    "        indices        = np.arange(len(batch))\n",
    "        class_dict     = {i:indices[labels==i] for i in unique_classes}\n",
    "\n",
    "        sampled_triplets = [list(it.product([x],[x],[y for y in unique_classes if x!=y])) for x in unique_classes]\n",
    "        print(sampled_triplets)\n",
    "        sampled_triplets = [x for y in sampled_triplets for x in y]\n",
    "\n",
    "        sampled_triplets = [[x for x in list(it.product(*[class_dict[j] for j in i])) if x[0]!=x[1]] for i in sampled_triplets]\n",
    "        sampled_triplets = [x for y in sampled_triplets for x in y]\n",
    "\n",
    "        #NOTE: The number of possible triplets is given by #unique_classes*(2*(samples_per_class-1)!)*(#unique_classes-1)*samples_per_class\n",
    "        #print('Sample values:')\n",
    "        #print(sampled_triplets, batch.shape[0])\n",
    "        sampled_triplets = random.sample(sampled_triplets, batch.shape[0])\n",
    "        return sampled_triplets\n",
    "\n",
    "\n",
    "    def semihardsampling(self, batch, labels):\n",
    "        \"\"\"\n",
    "        This methods finds all available triplets in a batch given by the classes provided in labels, and select\n",
    "        triplets based on semihard sampling introduced in 'Deep Metric Learning via Lifted Structured Feature Embedding'.\n",
    "        Args:\n",
    "            batch:  np.ndarray or torch.Tensor, batch-wise embedded training samples.\n",
    "            labels: np.ndarray or torch.Tensor, ground truth labels corresponding to batch.\n",
    "        Returns:\n",
    "            list of sampled data tuples containing reference indices to the position IN THE BATCH.\n",
    "        \"\"\"\n",
    "        if isinstance(labels, torch.Tensor): labels = labels.detach().numpy()\n",
    "        bs = batch.size(0)\n",
    "        #Return distance matrix for all elements in batch (BSxBS)\n",
    "        distances = self.pdist(batch.detach()).detach().cpu().numpy()\n",
    "\n",
    "        positives, negatives = [], []\n",
    "        anchors = []\n",
    "        for i in range(bs):\n",
    "            l, d = labels[i], distances[i]\n",
    "            anchors.append(i)\n",
    "            #1 for batchelements with label l\n",
    "            neg = labels!=l; pos = labels==l\n",
    "            #0 for current anchor\n",
    "            pos[i] = False\n",
    "\n",
    "            #Find negatives that violate triplet constraint semi-negatives\n",
    "            neg_mask = np.logical_and(neg,d<d[np.where(pos)[0]].max())\n",
    "            #Find positives that violate triplet constraint semi-hardly\n",
    "            pos_mask = np.logical_and(pos,d>d[np.where(neg)[0]].min())\n",
    "\n",
    "            if pos_mask.sum()>0:\n",
    "                positives.append(np.random.choice(np.where(pos_mask)[0]))\n",
    "            else:\n",
    "                positives.append(np.random.choice(np.where(pos)[0]))\n",
    "\n",
    "            if neg_mask.sum()>0:\n",
    "                negatives.append(np.random.choice(np.where(neg_mask)[0]))\n",
    "            else:\n",
    "                negatives.append(np.random.choice(np.where(neg)[0]))\n",
    "\n",
    "        sampled_triplets = [[a, p, n] for a, p, n in zip(anchors, positives, negatives)]\n",
    "        return sampled_triplets\n",
    "\n",
    "\n",
    "    def distanceweightedsampling(self, batch, labels, lower_cutoff=0.5, upper_cutoff=1.4):\n",
    "        \"\"\"\n",
    "        This methods finds all available triplets in a batch given by the classes provided in labels, and select\n",
    "        triplets based on distance sampling introduced in 'Sampling Matters in Deep Embedding Learning'.\n",
    "        Args:\n",
    "            batch:  np.ndarray or torch.Tensor, batch-wise embedded training samples.\n",
    "            labels: np.ndarray or torch.Tensor, ground truth labels corresponding to batch.\n",
    "            lower_cutoff: float, lower cutoff value for negatives that are too close to anchor embeddings. Set to literature value. They will be assigned a zero-sample probability.\n",
    "            upper_cutoff: float, upper cutoff value for positives that are too far away from the anchor embeddings. Set to literature value. They will be assigned a zero-sample probability.\n",
    "        Returns:\n",
    "            list of sampled data tuples containing reference indices to the position IN THE BATCH.\n",
    "        \"\"\"\n",
    "        if isinstance(labels, torch.Tensor): labels = labels.detach().cpu().numpy()\n",
    "        bs = batch.shape[0]\n",
    "\n",
    "        distances    = self.pdist(batch.detach()).clamp(min=lower_cutoff)\n",
    "\n",
    "\n",
    "\n",
    "        positives, negatives = [],[]\n",
    "        labels_visited = []\n",
    "        anchors = []\n",
    "\n",
    "        for i in range(bs):\n",
    "            neg = labels!=labels[i]; pos = labels==labels[i]\n",
    "            q_d_inv = self.inverse_sphere_distances(batch, distances[i], labels, labels[i])\n",
    "            #Sample positives randomly\n",
    "            pos[i] = 0\n",
    "            positives.append(np.random.choice(np.where(pos)[0]))\n",
    "            #Sample negatives by distance\n",
    "            negatives.append(np.random.choice(bs,p=q_d_inv))\n",
    "\n",
    "        sampled_triplets = [[a,p,n] for a,p,n in zip(list(range(bs)), positives, negatives)]\n",
    "        return sampled_triplets\n",
    "\n",
    "\n",
    "    def npairsampling(self, batch, labels):\n",
    "        \"\"\"\n",
    "        This methods finds N-Pairs in a batch given by the classes provided in labels in the\n",
    "        creation fashion proposed in 'Improved Deep Metric Learning with Multi-class N-pair Loss Objective'.\n",
    "        Args:\n",
    "            batch:  np.ndarray or torch.Tensor, batch-wise embedded training samples.\n",
    "            labels: np.ndarray or torch.Tensor, ground truth labels corresponding to batch.\n",
    "        Returns:\n",
    "            list of sampled data tuples containing reference indices to the position IN THE BATCH.\n",
    "        \"\"\"\n",
    "        if isinstance(labels, torch.Tensor):    labels = labels.detach().cpu().numpy()\n",
    "\n",
    "        label_set, count = np.unique(labels, return_counts=True)\n",
    "        label_set  = label_set[count>=2]\n",
    "        pos_pairs  = np.array([np.random.choice(np.where(labels==x)[0], 2, replace=False) for x in label_set])\n",
    "        neg_tuples = []\n",
    "\n",
    "        for idx in range(len(pos_pairs)):\n",
    "            neg_tuples.append(pos_pairs[np.delete(np.arange(len(pos_pairs)),idx),1])\n",
    "\n",
    "        neg_tuples = np.array(neg_tuples)\n",
    "\n",
    "        sampled_npairs = [[a,p,*list(neg)] for (a,p),neg in zip(pos_pairs, neg_tuples)]\n",
    "        return sampled_npairs\n",
    "\n",
    "\n",
    "    def pdist(self, A, eps = 1e-4):\n",
    "        \"\"\"\n",
    "        Efficient function to compute the distance matrix for a matrix A.\n",
    "        Args:\n",
    "            A:   Matrix/Tensor for which the distance matrix is to be computed.\n",
    "            eps: float, minimal distance/clampling value to ensure no zero values.\n",
    "        Returns:\n",
    "            distance_matrix, clamped to ensure no zero values are passed.\n",
    "        \"\"\"\n",
    "        prod = torch.mm(A, A.t())\n",
    "        norm = prod.diag().unsqueeze(1).expand_as(prod)\n",
    "        res = (norm + norm.t() - 2 * prod).clamp(min = 0)\n",
    "        return res.clamp(min = eps).sqrt()\n",
    "\n",
    "\n",
    "    def inverse_sphere_distances(self, batch, dist, labels, anchor_label):\n",
    "        \"\"\"\n",
    "        Function to utilise the distances of batch samples to compute their\n",
    "        probability of occurence, and using the inverse to sample actual negatives to the resp. anchor.\n",
    "        Args:\n",
    "            batch:        torch.Tensor(), batch for which the sampling probabilities w.r.t to the anchor are computed. Used only to extract the shape.\n",
    "            dist:         torch.Tensor(), computed distances between anchor to all batch samples.\n",
    "            labels:       np.ndarray, labels for each sample for which distances were computed in dist.\n",
    "            anchor_label: float, anchor label\n",
    "        Returns:\n",
    "            distance_matrix, clamped to ensure no zero values are passed.\n",
    "        \"\"\"\n",
    "        bs,dim       = len(dist),batch.shape[-1]\n",
    "\n",
    "        #negated log-distribution of distances of unit sphere in dimension <dim>\n",
    "        log_q_d_inv = ((2.0 - float(dim)) * torch.log(dist) - (float(dim-3) / 2) * torch.log(1.0 - 0.25 * (dist.pow(2))))\n",
    "        #Set sampling probabilities of positives to zero\n",
    "        log_q_d_inv[np.where(labels==anchor_label)[0]] = 0\n",
    "\n",
    "        q_d_inv     = torch.exp(log_q_d_inv - torch.max(log_q_d_inv)) # - max(log) for stability\n",
    "        #Set sampling probabilities of positives to zero\n",
    "        q_d_inv[np.where(labels==anchor_label)[0]] = 0\n",
    "\n",
    "        ### NOTE: Cutting of values with high distances made the results slightly worse.\n",
    "        # q_d_inv[np.where(dist>upper_cutoff)[0]]    = 0\n",
    "\n",
    "        #Normalize inverted distance for probability distr.\n",
    "        q_d_inv = q_d_inv/q_d_inv.sum()\n",
    "        return q_d_inv.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=1, sampling_method='random'):\n",
    "        \"\"\"\n",
    "        Basic Triplet Loss as proposed in 'FaceNet: A Unified Embedding for Face Recognition and Clustering'\n",
    "        Args:\n",
    "            margin:             float, Triplet Margin - Ensures that positives aren't placed arbitrarily close to the anchor.\n",
    "                                Similarl, negatives should not be placed arbitrarily far away.\n",
    "            sampling_method:    Method to use for sampling training triplets. Used for the Sampler-class.\n",
    "        \"\"\"\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin             = margin\n",
    "        self.sampler            = Sampler(method=sampling_method)\n",
    "\n",
    "    def triplet_distance(self, anchor, positive, negative):\n",
    "        \"\"\"\n",
    "        Compute triplet loss.\n",
    "        Args:\n",
    "            anchor, positive, negative: torch.Tensor(), resp. embeddings for anchor, positive and negative samples.\n",
    "        Returns:\n",
    "            triplet loss (torch.Tensor())\n",
    "        \"\"\"\n",
    "        return torch.nn.functional.relu((anchor-positive).pow(2).sum()-(anchor-negative).pow(2).sum()+self.margin)\n",
    "\n",
    "    def forward(self, batch, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch:   torch.Tensor() [(BS x embed_dim)], batch of embeddings\n",
    "            labels:  np.ndarray [(BS x 1)], for each element of the batch assigns a class [0,...,C-1]\n",
    "        Returns:\n",
    "            triplet loss (torch.Tensor(), batch-averaged)\n",
    "        \"\"\"\n",
    "        #Sample triplets to use for training.\n",
    "        print('in forward function:')\n",
    "        print(batch.shape, labels.shape)\n",
    "        sampled_triplets = self.sampler.give(batch, labels)\n",
    "        #Compute triplet loss\n",
    "        loss             = torch.stack([self.triplet_distance(batch[triplet[0],:],batch[triplet[1],:],batch[triplet[2],:]) for triplet in sampled_triplets])\n",
    "\n",
    "        return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standard N-Pair Loss.\n",
    "class NPairLoss(torch.nn.Module):\n",
    "    def __init__(self, l2=0.02):\n",
    "        \"\"\"\n",
    "        Basic N-Pair Loss as proposed in 'Improved Deep Metric Learning with Multi-class N-pair Loss Objective'\n",
    "        Args:\n",
    "            l2: float, weighting parameter for weight penality due to embeddings not being normalized.\n",
    "        Returns:\n",
    "            Nothing!\n",
    "        \"\"\"\n",
    "        super(NPairLoss, self).__init__()\n",
    "        self.sampler = Sampler(method='npair')\n",
    "        self.l2      = l2\n",
    "\n",
    "    def npair_distance(self, anchor, positive, negatives):\n",
    "        \"\"\"\n",
    "        Compute basic N-Pair loss.\n",
    "        Args:\n",
    "            anchor, positive, negative: torch.Tensor(), resp. embeddings for anchor, positive and negative samples.\n",
    "        Returns:\n",
    "            n-pair loss (torch.Tensor())\n",
    "        \"\"\"\n",
    "        return torch.log(1+torch.sum(torch.exp(anchor.mm((negatives-positive).transpose(0,1)))))\n",
    "\n",
    "    def weightsum(self, anchor, positive):\n",
    "        \"\"\"\n",
    "        Compute weight penalty.\n",
    "        NOTE: Only need to penalize anchor and positive since the negatives are created based on these.\n",
    "        Args:\n",
    "            anchor, positive: torch.Tensor(), resp. embeddings for anchor and positive samples.\n",
    "        Returns:\n",
    "            torch.Tensor(), Weight penalty\n",
    "        \"\"\"\n",
    "        return torch.sum(anchor**2+positive**2)\n",
    "\n",
    "    def forward(self, batch, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch:   torch.Tensor() [(BS x embed_dim)], batch of embeddings\n",
    "            labels:  np.ndarray [(BS x 1)], for each element of the batch assigns a class [0,...,C-1]\n",
    "        Returns:\n",
    "            n-pair loss (torch.Tensor(), batch-averaged)\n",
    "        \"\"\"\n",
    "        #Sample N-Pairs\n",
    "        sampled_npairs = self.sampler.give(batch, labels)\n",
    "        #Compute basic n=pair loss\n",
    "        loss           = torch.stack([self.npair_distance(batch[npair[0]:npair[0]+1,:],batch[npair[1]:npair[1]+1,:],batch[npair[2:],:]) for npair in sampled_npairs])\n",
    "        #Include weight penalty\n",
    "        loss           = loss + self.l2*torch.mean(torch.stack([self.weightsum(batch[npair[0],:], batch[npair[1],:]) for npair in sampled_npairs]))\n",
    "\n",
    "        return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = TripletLoss()\n",
    "#criterion = NPairLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/5\n",
      "----------\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "train Loss: 0.9836 Acc: 0.4918\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "val Loss: 0.9412 Acc: 0.4967\n",
      "\n",
      "Epoch 1/5\n",
      "----------\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "train Loss: 0.9836 Acc: 0.4918\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "val Loss: 0.9412 Acc: 0.5098\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "train Loss: 0.9836 Acc: 0.4836\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "val Loss: 0.9412 Acc: 0.5163\n",
      "\n",
      "Epoch 3/5\n",
      "----------\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "train Loss: 0.9836 Acc: 0.4795\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "val Loss: 0.9412 Acc: 0.5033\n",
      "\n",
      "Epoch 4/5\n",
      "----------\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "train Loss: 0.9836 Acc: 0.4836\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "val Loss: 0.9412 Acc: 0.5163\n",
      "\n",
      "Epoch 5/5\n",
      "----------\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "backward works\n",
      "train Loss: 0.9836 Acc: 0.4877\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "outputs\n",
      "torch.Size([16, 2])\n",
      "labels\n",
      "torch.Size([16])\n",
      "in forward function:\n",
      "torch.Size([16, 2]) torch.Size([16])\n",
      "[[(0, 0, 1)], [(1, 1, 0)]]\n",
      "val Loss: 0.9412 Acc: 0.5163\n",
      "\n",
      "Training complete in 3m 34s\n",
      "Best val Acc: 0.516340\n"
     ]
    }
   ],
   "source": [
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, \n",
    "                             optimizer_ft, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5, 4]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample([2,3,4,5,6,7,5],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TripletLoss()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, labels in dataloaders_dict['train']:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model_ft(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs)\n",
    "print(labels)\n",
    "print(criterion(outputs, labels))\n",
    "#print(criterion.backward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics_one_dataset(model, test_dataloader, device, k_vals, opt):\n",
    "    \"\"\"\n",
    "    Compute evaluation metrics on test-dataset, e.g. NMI, F1 and Recall @ k.\n",
    "    Args:\n",
    "        model:              PyTorch network, network to compute evaluation metrics for.\n",
    "        test_dataloader:    PyTorch Dataloader, dataloader for test dataset, should have no shuffling and correct processing.\n",
    "        device:             torch.device, Device to run inference on.\n",
    "        k_vals:             list of int, Recall values to compute\n",
    "        opt:                argparse.Namespace, contains all training-specific parameters.\n",
    "    Returns:\n",
    "        F1 score (float), NMI score (float), recall_at_k (list of float), data embedding (np.ndarray)\n",
    "    \"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    _ = model.eval()\n",
    "    n_classes = len(test_dataloader.dataset.avail_classes)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ### For all test images, extract features\n",
    "        target_labels, feature_coll = [],[]\n",
    "        final_iter = tqdm(test_dataloader, desc='Computing Evaluation Metrics...')\n",
    "        image_paths= [x[0] for x in test_dataloader.dataset.image_list]\n",
    "        for idx,inp in enumerate(final_iter):\n",
    "            input_img,target = inp[-1], inp[0]\n",
    "            target_labels.extend(target.numpy().tolist())\n",
    "            out = model(input_img.to(device))\n",
    "            feature_coll.extend(out.cpu().detach().numpy().tolist())\n",
    "\n",
    "        target_labels = np.hstack(target_labels).reshape(-1,1)\n",
    "        feature_coll  = np.vstack(feature_coll).astype('float32')\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        ### Set Faiss CPU Cluster index\n",
    "        cpu_cluster_index = faiss.IndexFlatL2(feature_coll.shape[-1])\n",
    "        kmeans            = faiss.Clustering(feature_coll.shape[-1], n_classes)\n",
    "        kmeans.niter = 20\n",
    "        kmeans.min_points_per_centroid = 1\n",
    "        kmeans.max_points_per_centroid = 1000000000\n",
    "\n",
    "        ### Train Kmeans\n",
    "        kmeans.train(feature_coll, cpu_cluster_index)\n",
    "        computed_centroids = faiss.vector_float_to_array(kmeans.centroids).reshape(n_classes, feature_coll.shape[-1])\n",
    "\n",
    "        ### Assign feature points to clusters\n",
    "        faiss_search_index = faiss.IndexFlatL2(computed_centroids.shape[-1])\n",
    "        faiss_search_index.add(computed_centroids)\n",
    "        _, model_generated_cluster_labels = faiss_search_index.search(feature_coll, 1)\n",
    "\n",
    "        ### Compute NMI\n",
    "        NMI = metrics.cluster.normalized_mutual_info_score(model_generated_cluster_labels.reshape(-1), target_labels.reshape(-1))\n",
    "\n",
    "\n",
    "        ### Recover max(k_vals) nearest neighbours to use for recall computation\n",
    "        faiss_search_index  = faiss.IndexFlatL2(feature_coll.shape[-1])\n",
    "        faiss_search_index.add(feature_coll)\n",
    "        _, k_closest_points = faiss_search_index.search(feature_coll, int(np.max(k_vals)+1))\n",
    "        k_closest_classes   = target_labels.reshape(-1)[k_closest_points[:,1:]]\n",
    "\n",
    "        ### Compute Recall\n",
    "        recall_all_k = []\n",
    "        for k in k_vals:\n",
    "            recall_at_k = np.sum([1 for target, recalled_predictions in zip(target_labels, k_closest_classes) if target in recalled_predictions[:k]])/len(target_labels)\n",
    "            recall_all_k.append(recall_at_k)\n",
    "\n",
    "        ### Compute F1 Score\n",
    "        F1 = f1_score(model_generated_cluster_labels, target_labels, feature_coll, computed_centroids)\n",
    "\n",
    "    return F1, NMI, recall_all_k, feature_coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloaders_dict['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloaders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-ed2a3397b6e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dataloaders' is not defined"
     ]
    }
   ],
   "source": [
    "len(dataloaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
